{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T07:27:37.638427Z",
     "start_time": "2021-02-13T07:27:37.472Z"
    }
   },
   "outputs": [],
   "source": [
    "import java.io.File\n",
    "\n",
    "val tensorsFiles = new File(\"sample_tensors_HaTen\").listFiles\n",
    "    .map(_.getName)\n",
    "    .filter(f => f.startsWith(\"tensor\") && !f.contains(\"clusters\")).toList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run CP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T22:11:13.777688Z",
     "start_time": "2021-02-11T22:11:11.296Z"
    }
   },
   "outputs": [],
   "source": [
    "import scala.collection.mutable.{Map => MMap}\n",
    "import scala.sys.process._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T22:11:14.366319Z",
     "start_time": "2021-02-11T22:11:12.005Z"
    }
   },
   "outputs": [],
   "source": [
    "def appendToEnv(key: String, value: String) = scala.util.Properties.envOrNone(key) match {\n",
    "    case Some(v) if v.nonEmpty => s\"$v${System getProperty \"path.separator\"}$value\"\n",
    "    case _ => value\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T17:32:00.400810Z",
     "start_time": "2021-02-16T06:57:25.295Z"
    }
   },
   "outputs": [],
   "source": [
    "val hadoopPath = \"\"\n",
    "var timeCPALSHaTen = MMap[Int, MMap[Int, MMap[Double, Int]]]()\n",
    "val outputPath = \"output\"\n",
    "val logPath = \"out.log\"\n",
    "\n",
    "for (dimension <- 3 to 3;\n",
    "     size <- List(100, 1000, 10000, 100000);\n",
    "     sparsity <- List(1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10).reverse) {\n",
    "    val fileName = s\"tensor_${dimension}_${size}_${sparsity}.csv\"\n",
    "    if (tensorsFiles.contains(fileName)) {\n",
    "        println(fileName)\n",
    "        val nbIterations = 5\n",
    "        var endTime = 0\n",
    "        try {\n",
    "            s\"$hadoopPath/bin/hadoop fs -put sample_tensors_HaTen/$fileName .\" !!\n",
    "        } catch {\n",
    "            case t: Throwable => println(t)\n",
    "        }\n",
    "        \n",
    "        for (j <- 0 until nbIterations) {   \n",
    "            val dimensionString = (for (_ <- 0 until dimension) yield size).mkString(\":\")\n",
    "            val arguments = Array[String](dimensionString, \"3\", \"40\", \"5\", fileName, outputPath, logPath).mkString(\" \")\n",
    "            println(s\"./run_parafacnn.sh $arguments\")\n",
    "            \n",
    "            println(java.util.Calendar.getInstance().getTime())\n",
    "            val startTime = System.currentTimeMillis()\n",
    "            \n",
    "            val output = Process(s\"./HaTen2_run_parafacnn.sh $arguments\", \n",
    "                                 new java.io.File(\"lib\"), \n",
    "                                 \"PATH\" -> appendToEnv(\"PATH\", s\"$hadoopPath/bin\")) ! ProcessLogger(_ => {}, _ => {})\n",
    "            \n",
    "            endTime += (System.currentTimeMillis() - startTime).toInt\n",
    "\n",
    "            println(\"Execution time: \" + (endTime / 1000) + \"s\")\n",
    "        }\n",
    "        val finalTime = (endTime / nbIterations).toInt\n",
    "        var dimMap = timeCPALSHaTen.getOrElse(dimension, MMap[Int, MMap[Double, Int]]())\n",
    "        var sizeMap = dimMap.getOrElse(size, MMap[Double, Int]())\n",
    "        sizeMap = sizeMap + (sparsity -> finalTime)\n",
    "        dimMap = dimMap + (size -> sizeMap)\n",
    "        timeCPALSHaTen(dimension) = dimMap\n",
    "    } \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T06:08:36.009510Z",
     "start_time": "2021-02-12T06:08:35.149Z"
    }
   },
   "outputs": [],
   "source": [
    "import $ivy.`com.github.tototoshi::scala-csv:1.3.6`\n",
    "import com.github.tototoshi.csv._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T17:33:06.686450Z",
     "start_time": "2021-02-16T17:33:06.435Z"
    }
   },
   "outputs": [],
   "source": [
    "val f = new java.io.File(s\"\"\"results/benchmarkHaTen.csv\"\"\")\n",
    "val fileExists = f.exists()\n",
    "val writer = CSVWriter.open(f, append = true)\n",
    "if (!fileExists) {\n",
    "    writer.writeRow(List[String](\"dimension\", \"size\", \"sparsity\", \"time\"))\n",
    "}\n",
    "for ((dimension, r1) <- timeCPALSHaTen; (size, r2) <- r1; (sparsity, time) <- r2) {\n",
    "    println(List[Any](dimension, size, sparsity, time))\n",
    "    writer.writeRow(List[Any](dimension, size, sparsity, time))\n",
    "}\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
