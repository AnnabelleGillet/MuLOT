{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T09:59:39.399100Z",
     "start_time": "2021-02-08T09:59:34.130Z"
    }
   },
   "outputs": [],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:2.2.0`\n",
    "import $ivy.`org.apache.spark::spark-mllib:2.2.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T09:59:40.264383Z",
     "start_time": "2021-02-08T09:59:34.773Z"
    }
   },
   "outputs": [],
   "source": [
    "val currentDirectory = new java.io.File(\".\").getCanonicalPath\n",
    "val path = java.nio.file.FileSystems.getDefault().getPath(s\"$currentDirectory/lib/sambaten_2.11-0.1.jar\")\n",
    "val x = ammonite.ops.Path(path)\n",
    "interp.load.cp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T09:59:40.946947Z",
     "start_time": "2021-02-08T09:59:35.505Z"
    }
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.SparkContext\n",
    "import org.apache.spark.sql.{DataFrame, SparkSession}\n",
    "import edu.ucr.sambaten._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T09:59:43.696119Z",
     "start_time": "2021-02-08T09:59:36.973Z"
    }
   },
   "outputs": [],
   "source": [
    "implicit val spark = {\n",
    "    val MAX_MEMORY = \"126g\"\n",
    "    SparkSession.builder()\n",
    "        .config(\"spark.executor.memory\", MAX_MEMORY)\n",
    "        .config(\"spark.driver.memory\", MAX_MEMORY)\n",
    "        .appName(\"BenchmarkSamBaTen\")\n",
    "        .master(\"local[*]\")\n",
    "        .getOrCreate()\n",
    "}\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "import spark.implicits._\n",
    "\n",
    "spark.sparkContext.getConf.getAll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to run CP-ALS with SamBaTen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T09:59:44.277042Z",
     "start_time": "2021-02-08T09:59:40.077Z"
    }
   },
   "outputs": [],
   "source": [
    "implicit val sc = spark.sparkContext\n",
    "\n",
    "def dataFrameToCoordinateTensor(df: DataFrame, order: Int, dimensionsSize: Int)(implicit sc: SparkContext): CoordinateTensor = {\n",
    "    val entries = df.map(e => {\n",
    "        val seq = for (i <- 0 until order) yield e.getString(e.fieldIndex(s\"d$i\")).toInt\n",
    "        TEntry(new Coordinate(seq), e.getString(e.fieldIndex(\"val\")).toDouble)\n",
    "    }).rdd\n",
    "    val shape = new Coordinate(for (_ <- 0 until order) yield dimensionsSize)\n",
    "    val nnz = df.count()\n",
    "    new CoordinateTensor(entries, shape, nnz.toInt)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T09:59:44.669806Z",
     "start_time": "2021-02-08T09:59:42.559Z"
    }
   },
   "outputs": [],
   "source": [
    "case class TensorDf(df: DataFrame, order: Int, dimensionsSize: Int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T09:59:45.123946Z",
     "start_time": "2021-02-08T09:59:44.817Z"
    }
   },
   "outputs": [],
   "source": [
    "import java.io.File\n",
    "\n",
    "val tensorsFiles = new File(\"sample_tensors\").listFiles\n",
    "    .map(_.getName)\n",
    "    .filter(f => f.startsWith(\"tensor\") && !f.contains(\"clusters\")).toList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T09:59:51.356915Z",
     "start_time": "2021-02-08T09:59:45.917Z"
    }
   },
   "outputs": [],
   "source": [
    "val tensors = (for (tensorFile <- tensorsFiles) yield {\n",
    "    val name = tensorFile.replace(\".csv\", \"\").replace(\"tensor_\", \"\").split(\"_\")\n",
    "    val nbDimensions = name(0).toInt\n",
    "    val size = name(1).toLong\n",
    "    (tensorFile -> \n",
    "        TensorDf(spark.read.option(\"header\", true).csv(s\"sample_tensors/$tensorFile\"), nbDimensions, size.toInt))\n",
    "}).toMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run CP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T09:59:51.673393Z",
     "start_time": "2021-02-08T09:59:49.139Z"
    }
   },
   "outputs": [],
   "source": [
    "import scala.collection.mutable.{Map => MMap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-08T21:28:25.022Z"
    }
   },
   "outputs": [],
   "source": [
    "var timeCPALSSamBaTen = MMap[Int, MMap[Int, MMap[Double, Int]]]()\n",
    "\n",
    "for (dimension <- 3 to 3; \n",
    "     size <- List(100, 1000, 10000, 100000);\n",
    "     sparsity <- List(1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10).reverse) {\n",
    "    val fileName = s\"tensor_${dimension}_${size}_${sparsity}.csv\"\n",
    "    if (tensors.contains(fileName)) {\n",
    "        println(fileName)\n",
    "        val nbIterations = 1//5\n",
    "        var endTime = 0\n",
    "        for (j <- 0 until nbIterations) {\n",
    "            spark.catalog.clearCache()\n",
    "            val _t = tensors.get(fileName).get\n",
    "            val tensor = dataFrameToCoordinateTensor(_t.df, _t.order, _t.dimensionsSize)\n",
    "            \n",
    "            val startTime = System.currentTimeMillis()\n",
    "\n",
    "            val cpAls = new CPALS().setAttr(3, 5, 1e-100)\n",
    "            cpAls.run(tensor)\n",
    "\n",
    "            endTime += (System.currentTimeMillis() - startTime).toInt\n",
    "\n",
    "            println(\"Execution time: \" + (endTime / 1000) + \"s\")\n",
    "        }\n",
    "        val finalTime = (endTime / nbIterations).toInt\n",
    "        var dimMap = timeCPALSSamBaTen.getOrElse(dimension, MMap[Int, MMap[Double, Int]]())\n",
    "        var sizeMap = dimMap.getOrElse(size, MMap[Double, Int]())\n",
    "        sizeMap = sizeMap + (sparsity -> finalTime)\n",
    "        dimMap = dimMap + (size -> sizeMap)\n",
    "        timeCPALSSamBaTen(dimension) = dimMap\n",
    "    } \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T17:04:18.880245Z",
     "start_time": "2021-02-11T17:04:17.414Z"
    }
   },
   "outputs": [],
   "source": [
    "import $ivy.`com.github.tototoshi::scala-csv:1.3.6`\n",
    "import com.github.tototoshi.csv._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T17:04:21.413272Z",
     "start_time": "2021-02-11T17:04:20.486Z"
    }
   },
   "outputs": [],
   "source": [
    "val f = new java.io.File(s\"\"\"results/benchmarkSamBaTen.csv\"\"\")\n",
    "val fileExists = f.exists()\n",
    "val writer = CSVWriter.open(f, append = true)\n",
    "if (!fileExists) {\n",
    "    writer.writeRow(List[String](\"dimension\", \"size\", \"sparsity\", \"time\"))\n",
    "}\n",
    "for ((dimension, r1) <- timeCPALSSamBaTen; (size, r2) <- r1; (sparsity, time) <- r2) {\n",
    "    println(List[Any](dimension, size, sparsity, time))\n",
    "    writer.writeRow(List[Any](dimension, size, sparsity, time))\n",
    "}\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Scala (2.11.12)",
   "language": "scala",
   "name": "scala211"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.11.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
