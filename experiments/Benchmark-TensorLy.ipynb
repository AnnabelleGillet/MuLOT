{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T13:27:11.909263Z",
     "start_time": "2022-06-24T13:27:11.904099Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import parafac\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T14:53:12.186806Z",
     "start_time": "2022-06-24T14:29:09.519330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_tensors/tensor_3_100_0.001.csv\n",
      "reconstruction error=0.9973610085342283\n",
      "iteration 1, reconstruction error: 0.9958534331381325, decrease = 0.001507575396095806, unnormalized = 1797.60143699377\n",
      "iteration 2, reconstruction error: 0.9954090838502094, decrease = 0.0004443492879230293, unnormalized = 1796.7993481602953\n",
      "iteration 3, reconstruction error: 0.9947368314397044, decrease = 0.0006722524105050587, unnormalized = 1795.585874511529\n",
      "iteration 4, reconstruction error: 0.994249547619266, decrease = 0.0004872838204383889, unnormalized = 1794.7062851395433\n",
      "iteration 5, reconstruction error: 0.9940368850145169, decrease = 0.00021266260474905874, unnormalized = 1794.322410774932\n",
      "552\n",
      "sample_tensors/tensor_3_100_0.01.csv\n",
      "reconstruction error=0.9955464641565058\n",
      "iteration 1, reconstruction error: 0.9953451098720206, decrease = 0.0002013542844852001, unnormalized = 5740.051110393578\n",
      "iteration 2, reconstruction error: 0.9952734018219067, decrease = 7.170805011391668e-05, unnormalized = 5739.637577571044\n",
      "iteration 3, reconstruction error: 0.9952196036573214, decrease = 5.3798164585283637e-05, unnormalized = 5739.327329184527\n",
      "iteration 4, reconstruction error: 0.9951697473252206, decrease = 4.98563321008616e-05, unnormalized = 5739.0398129335335\n",
      "iteration 5, reconstruction error: 0.9951205635457844, decrease = 4.9183779436190456e-05, unnormalized = 5738.7561752233905\n",
      "287\n",
      "sample_tensors/tensor_3_100_0.1.csv\n",
      "reconstruction error=0.9631542048254647\n",
      "iteration 1, reconstruction error: 0.9630187451905253, decrease = 0.00013545963493932778, unnormalized = 17149.678073340394\n",
      "iteration 2, reconstruction error: 0.9629598358178891, decrease = 5.8909372636195556e-05, unnormalized = 17148.629000535468\n",
      "iteration 3, reconstruction error: 0.9629235387949198, decrease = 3.62970229693671e-05, unnormalized = 17147.982614094857\n",
      "iteration 4, reconstruction error: 0.9628977966635534, decrease = 2.5742131366413012e-05, unnormalized = 17147.5241917972\n",
      "iteration 5, reconstruction error: 0.9628802276130293, decrease = 1.7569050524079977e-05, unnormalized = 17147.21131776225\n",
      "340\n",
      "sample_tensors/tensor_3_1000_1.0E-5.csv\n",
      "reconstruction error=0.9998577216148625\n",
      "iteration 1, reconstruction error: 0.9997173118089917, decrease = 0.00014040980587082252, unnormalized = 5803.719724342265\n",
      "iteration 2, reconstruction error: 0.9996857258270415, decrease = 3.158598195018847e-05, unnormalized = 5803.536356319833\n",
      "iteration 3, reconstruction error: 0.9996671385116853, decrease = 1.858731535619995e-05, unnormalized = 5803.428450247306\n",
      "iteration 4, reconstruction error: 0.9996534515947478, decrease = 1.368691693748314e-05, unnormalized = 5803.348992755816\n",
      "iteration 5, reconstruction error: 0.9996404916221711, decrease = 1.2959972576775947e-05, unnormalized = 5803.273755438644\n",
      "115604\n",
      "sample_tensors/tensor_3_1000_1.0E-4.csv\n",
      "reconstruction error=0.999963870397158\n",
      "iteration 1, reconstruction error: 0.9999576058476648, decrease = 6.26454949315125e-06, unnormalized = 18244.651862993713\n",
      "iteration 2, reconstruction error: 0.9999575824919308, decrease = 2.3355734013463803e-08, unnormalized = 18244.65143685841\n",
      "iteration 3, reconstruction error: 0.9999575347427782, decrease = 4.774915263183743e-08, unnormalized = 18244.65056565481\n",
      "iteration 4, reconstruction error: 0.9999573563440929, decrease = 1.783986852688102e-07, unnormalized = 18244.647310694912\n",
      "iteration 5, reconstruction error: 0.999956687517294, decrease = 6.688267988330665e-07, unnormalized = 18244.635107665476\n",
      "117713\n",
      "sample_tensors/tensor_3_1000_0.001.csv\n",
      "reconstruction error=0.9996191145210304\n",
      "iteration 1, reconstruction error: 0.9996167633795094, decrease = 2.3511415209176434e-06, unnormalized = 57745.89125068488\n",
      "iteration 2, reconstruction error: 0.9996158645094055, decrease = 8.988701039047697e-07, unnormalized = 57745.839324729684\n",
      "iteration 3, reconstruction error: 0.9996153533331116, decrease = 5.111762939602471e-07, unnormalized = 57745.80979508216\n",
      "iteration 4, reconstruction error: 0.9996150217384919, decrease = 3.315946196513764e-07, unnormalized = 57745.7906395142\n",
      "iteration 5, reconstruction error: 0.9996147857582184, decrease = 2.3598027354410078e-07, unnormalized = 57745.77700739866\n",
      "104597\n",
      "sample_tensors/tensor_3_1000_0.01.csv\n",
      "reconstruction error=0.996256707955647\n",
      "iteration 1, reconstruction error: 0.9962552159447261, decrease = 1.4920109209226595e-06, unnormalized = 181447.1353429336\n",
      "iteration 2, reconstruction error: 0.9962545279495998, decrease = 6.879951263139006e-07, unnormalized = 181447.01003895243\n",
      "iteration 3, reconstruction error: 0.9962541176675711, decrease = 4.1028202868442776e-07, unnormalized = 181446.9353146272\n",
      "iteration 4, reconstruction error: 0.9962538267069497, decrease = 2.909606213741256e-07, unnormalized = 181446.8823222108\n",
      "iteration 5, reconstruction error: 0.9962536021045465, decrease = 2.2460240323152192e-07, unnormalized = 181446.84141556156\n",
      "119157\n",
      "sample_tensors/tensor_3_1000_0.1.csv\n",
      "reconstruction error=0.963645959481563\n",
      "iteration 1, reconstruction error: 0.9636445109006431, decrease = 1.4485809198827582e-06, unnormalized = 542797.7423452839\n",
      "iteration 2, reconstruction error: 0.96364384965635, decrease = 6.612442930986617e-07, unnormalized = 542797.3698823005\n",
      "iteration 3, reconstruction error: 0.9636434406364242, decrease = 4.0901992581776625e-07, unnormalized = 542797.139491228\n",
      "iteration 4, reconstruction error: 0.9636431652108589, decrease = 2.754255652437365e-07, unnormalized = 542796.9843506411\n",
      "iteration 5, reconstruction error: 0.963642973968383, decrease = 1.9124247585544651e-07, unnormalized = 542796.8766283608\n",
      "123191\n",
      "sample_tensors/tensor_3_10000_1.0E-7.csv\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 7.28 TiB for an array with shape (10000, 10000, 10000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-bf56e4afb0fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;31m# Build a 3 order tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mtensor_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdimension_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimension_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimension_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mtensor_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 7.28 TiB for an array with shape (10000, 10000, 10000) and data type float64"
     ]
    }
   ],
   "source": [
    "dimension = 3\n",
    "for dimension_size in [100, 1000, 10000, 100000]:\n",
    "    for sparsity in reversed([\"0.1\", \"0.01\", \"0.001\", \"1.0E-4\", \"1.0E-5\", \"1.0E-6\", \"1.0E-7\", \"1.0E-8\", \"1.0E-9\", \"1.0E-10\"]):\n",
    "        file = f\"sample_tensors/tensor_{dimension}_{dimension_size}_{sparsity}.csv\"\n",
    "        # Check if file exists\n",
    "        if (os.path.exists(file)):\n",
    "            print(file)\n",
    "            # Build a 3 order tensor\n",
    "            data = np.genfromtxt(file, dtype = float, delimiter = ',', names = True)\n",
    "            tensor_data = np.zeros((dimension_size, dimension_size, dimension_size))\n",
    "            for x, y, z, value in data:\n",
    "                tensor_data[int(x), int(y), int(z)] = value\n",
    "            tensor = tl.tensor(tensor_data)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            # Run decomposition\n",
    "            parafac(tensor, rank = 3, n_iter_max = 6, tol = -1.0, verbose = True)\n",
    "            end_time = time.time()\n",
    "            execution_time = end_time - start_time\n",
    "            print(int(execution_time * 1000))\n",
    "            # Write result\n",
    "            file_result = open('results/benchmarkTensorLy.csv', 'a')\n",
    "            file_result.write(f\"{dimension},{dimension_size},{sparsity},{int(execution_time * 1000)}\\n\")\n",
    "            file_result.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
